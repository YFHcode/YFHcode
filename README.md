<div id="header" align="center">
  <img src="https://media.giphy.com/media/M9gbBd9nbDrOTu1Mqx/giphy.gif" width="100"/>
</div>

<div id="badges" align="center">
  <a href="https://www.linkedin.com/in/youssef-el-fhayel/">
    <img src="https://img.shields.io/badge/LinkedIn-blue?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn Badge"/>
  </a>
  <a href="mailto:youssef.el-fhayel@esi.ac.ma">
    <img src="https://img.shields.io/badge/Email-red?style=for-the-badge&logo=gmail&logoColor=white" alt="Email Badge"/>
  </a>
</div>

<div align="center">
  <img src="https://komarev.com/ghpvc/?username=yfhcode&style=flat-square&color=blue" alt="Profile Views"/>
</div>

<h1 align="center">
  Hey there, I'm Youssef EL F'HAYEL
  <img src="https://media.giphy.com/media/hvRJCLFzcasrR4ia7z/giphy.gif" width="30px"/>
</h1>

---

### 👨‍💻 About Me

I’m **Youssef EL F'HAYEL**, a **Junior Data Engineer / Big Data Engineer** specializing in **Big Data**, **Distributed Systems**, and **Cloud Computing (GCP)**. I have hands-on experience in designing, developing, and deploying end-to-end data engineering solutions that drive real-time analytics, support AI models, and enable scalable, resilient data architectures. My competencies include:

- **Big Data Processing**: Expertise in **Apache Spark** (Structured Streaming, Spark ML) and **Hadoop Ecosystem** (HDFS, Hive) for high-performance, distributed data processing.
- **Data Pipeline Development**: Proficient in building ETL and real-time data ingestion pipelines using **Apache Kafka**, **Apache Beam**, and **Google Cloud Dataflow**, ensuring seamless integration from diverse data sources.
- **Cloud Data Systems (GCP)**: Skilled in Google Cloud services such as **BigQuery**, **Dataflow**, **Pub/Sub**, **Datastream**, and **Cloud Storage** to build robust, scalable, and cost-effective cloud architectures.
- **Data Quality and Optimization**: Implement data quality checks during ETL processes using Dataflow and design data systems optimized for performance and resource efficiency with tools like **Delta Lake** and **Terraform**.
- **AI and ML Integration**: Experience with tuning and deploying AI models, including Large Language Models (LLMs), for SQL generation, natural language processing, and real-time predictions in data engineering workflows.

I'm passionate about leveraging data engineering to drive insights, streamline operations, and deliver impactful solutions. Let’s connect to discuss data-driven innovations and explore new opportunities in the world of big data and cloud computing!

---

### 🛠️ Technologies & Tools

#### Programming & Query Languages
- **Python, SQL, Scala, Java**: Data processing, ETL scripting, and distributed computing
- **R**: Statistical analysis and data manipulation

#### Data Engineering & Big Data Tools
- **Apache Spark** (Structured Streaming, ML), **Apache Kafka**, **Apache Airflow** for workflow orchestration
- **Delta Lake**: Efficient data storage and retrieval
- **Apache Beam**: Unified model for batch and streaming data processing

#### Cloud Platforms
- **Google Cloud Platform (GCP)**:
  - **BigQuery**: Data warehousing and analytics
  - **Dataflow**: Real-time data processing
  - **Pub/Sub**: Messaging and event-driven systems
  - **Datastream**: Continuous data replication
  - **Terraform**: Infrastructure provisioning and automation

#### Additional Tools
- **Docker**: Containerization for application scaling
- **FastAPI**: API development for data access and integration
- **Power BI**: Data visualization for business insights
- **Version Control**: Git for source code management

---

### 📂 Featured Projects

- **[Real-Time Data Replication from Postgres to BigQuery](https://github.com/yfhcode/gcp-data-replication)**  
  Implemented a data replication process using **Google Datastream** to ensure real-time synchronization between Postgres and BigQuery, enabling up-to-date analytics for business decision-making.

- **[Real-Time Streaming Pipeline with Apache Kafka and Spark Structured Streaming](https://github.com/yfhcode/real-time-kafka-spark)**  
  Built a robust data pipeline using **Apache Kafka** for data ingestion and **Spark Structured Streaming** for real-time data transformations, with integrated data quality checks and Delta Lake storage.

- **[AI Model Deployment for SQL Generation using LLMs](https://github.com/yfhcode/llm-sql-generator)**  
  Fine-tuned and deployed a **Large Language Model (Gemma-7b)** to generate SQL queries from natural language, incorporating optimization techniques such as quantization and Low-Rank Adaptation to reduce model size and GPU usage.

- **[GCP-Based Data Lake for Real-Time Analytics](https://github.com/yfhcode/gcp-data-lake)**  
  Designed and implemented a scalable data lake on GCP using **Cloud Storage**, **BigQuery**, and **Dataflow**, supporting real-time and batch processing for comprehensive analytics capabilities.

---

### 🌐 Recent Blog Posts

> I write about data engineering, big data solutions, and cloud architecture. Here are a few recent articles:

- [Building Scalable Data Pipelines with Apache Kafka and Spark](https://medium.com/@yfhcode/kafka-spark-pipelines)
- [Data Lake vs. Data Warehouse on Google Cloud Platform](https://medium.com/@yfhcode/gcp-data-lake-vs-warehouse)
- [Optimizing Big Data Workflows with Delta Lake](https://medium.com/@yfhcode/delta-lake-optimization)

---

### 📈 GitHub Stats

<div align="center">
  <a href="https://git.io/streak-stats">
    <img src="http://github-readme-streak-stats.herokuapp.com?user=yfhcode&theme=dark&background=000000" alt="GitHub Streak"/>
  </a>
  <br>
  <a href="https://github.com/anuraghazra/github-readme-stats">
    <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=yfhcode&layout=compact&theme=vision-friendly-dark" alt="Top Languages"/>
  </a>
</div>

---

### 💬 Let's Connect

I’m always open to connecting with data enthusiasts and professionals in data engineering, big data, and cloud computing. Feel free to reach out on [LinkedIn](https://www.linkedin.com/in/youssef-el-fhayel/) or email me at youssef.el-fhayel@esi.ac.ma. Let’s innovate and build data-driven solutions together!
